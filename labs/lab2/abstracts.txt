In addressing the need for successful frameworks to break down understudy execution, this study presents a profound learning-based approach for thorough understudy execution examination inside instructive establishments. The framework intends to evaluate understudies' presentation levels and distinguish those qualified for positions, needing extra help, or in danger of exiting. Utilizing a Long Momentary Memory (LSTM) model, a sort of intermittent brain organization (RNN), the proposed framework predicts fourth-year understudies' presentation by utilizing three years of verifiable understudy marks information to catch fleeting examples and conditions. Broad testing and assessment show the LSTM model's surprising exactness, accomplishing an accuracy of 99.8% in distinctive understudies’ exhibition levels. Through the force of profound realizing, this framework engages instructive establishments to precisely separate between high-performing, low-performing, and in-danger understudies, working with vocation arranging and giving designated open doors to understudy positions. In addition, it promotes good help and mediation for students who are at risk of dropping out and improving real standards. By introducing deep learning strategies, especially LSTM models, this research provides valuable experience and direct prospects for investigating the implementation of non-earning people, empowering learning organizations to follow making informed choices, and showing direction and mediation. Finally, the framework that is being developed can improve the result of education without achieving it by enhancing dynamic changes and encouraging individual contributions in educational areas.
-next-
In the field of sentiment analysis, the notion of aspect category identification lays emphasis on identifying the aspect categories in a specific review phrase. The purpose of this research is to propose a novel approach to the identification of aspect categories in reviews that are published in Hindi. The training and evaluation of a supervised model that is based on deep learning enable the extraction of aspect categories. Every experiment is carried out with a well-accepted Hindi dataset. One of the challenges that are involved in aspect category recognition is the classification of text that has several labels. The utilization of a deep neural network that is founded on BiLSTM leads to an enhancement of the category detection outcomes. The results came out with an F-score of 0.8345 and an accuracy of 93.91% when applied to the well-known Hindi dataset. The offered architecture, in conjunction with the results that were achieved, gives a great deal of significance because it serves as a fundamental resource for future research and activities related to the issue. In this study, a deep-learning architecture is proposed for the aim of detecting aspect categories in Hindi. The outcomes of this architecture are both new and state-of-the-art in their respective fields.
-next-
Digital forensics has gained a high degree of attention recently due to the benefits it has to offer in investigating cybercrimes by analyzing and presenting digital evidence. It aims to highlight any correlations related to such crimes. Since digital forensics techniques are capable of providing robust and credible evidence, they have been used in different contexts and are accepted by law enforcement agencies. Social media forensics, a subdomain of digital forensics, has also been widely used to investigate digital crimes and suspicious activities on social media platforms. In addition to the challenges associated with digital forensics, such as anti-forensics, social media forensics also faces several obstacles, such as privacy and big data issues. This research proposes a dynamic methodology that utilizes digital forensics techniques to improve the investigation of cybercrimes committed on social media platforms. The proposed methodology offers a high level of flexibility, including choosing the type of crime, the platform used, and the investigation scenario. As part of the contribution of this research, the proposed methodology is used to detect suspicious activities associated with the COVID-19 pandemic. Various techniques and tools are used to evaluate the methodology such as VADER for tweet classification and other tools for collecting and extracting tweets’ information and correlation. The results indicate that the methodology is simple and capable of handling the digital evidence collected, as well as identifying credible relations between the data. The proposed methodology could also be extended in many ways to handle other challenges and limitations associated with digital forensics in general and social media forensics in particular.
-next-
Fuzzy logic serves as a computational modeling method, particularly prominent in the research domain of decision models. To assess the prevalent trends in the utilization of fuzzy logic in the research landscape of decision models and its common combinations with other methods, a conceptual model for article review was developed. This study involved three simple stages: Bibliometric analysis, article review and model construction. The findings indicate an exponential growth in the use of fuzzy logic according to 10,530 documents in ten years, with the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) emerging as the widely favored method combined with fuzzy logic in decision model research (according to 11 documents in the year 2023). Additionally, a comprehensive conceptual model for bibliometric analysis-based reviewing was designed using an object-oriented approach; via UML tools class (with 20 identified classes), sequence and use case (with 3 identified use cases) diagram.
-next-
A significant threat to people's health all over the world is skin cancer. The purpose of this research is to improve the detection of skin cancer by utilizing a CNN classification model that makes use of preprocessing and augmentation techniques. The HAM10000 dataset is used, and the imbalance it contains is addressed by resizing the images to 120×120 pixels and removing hair. Increasing the diversity of datasets through the use of data augmentation techniques is beneficial to the modeling and evaluation processes. In order to achieve the best possible classification of skin lesions, the proposed CNN architecture incorporates layers that have been carefully tuned. The data is divided into three different sets: Training, validation, and testing. The evaluation metrics, which include accuracy, precision, recall, and F1 score, all point to a highly successful performance of 0.932. This analysis demonstrates that the model is superior to other approaches to skin lesion classification, which signifies that it has the potential to be an effective instrument for the early detection of cancer.
-next-
In this study, authorship attribution in Arabic poetry will be conducted to determine the authorship of a specified text after documents with recognized authorships have been allocated. This work also measures the impact performance of Naïve Bayes, Support Vector Machine and Linear discriminant analysis for Arabic poetry authorship attribution using text mining classification. Several features such as lexical features, character features, structural features, poetry features, syntactic features, semantic features and specific word features are utilized as the input data for text mining, using classification algorithms Linear discriminant analysis, Support Vector Machine and Naïve Bayes by Arabic Poetry Authorship Attribution Model (APAAM). The dataset of Arabic poetry is divided into two sets: known poetic in training dataset texts and anonymous poetic texts in a test dataset part. In the experiment, a set of 114 random poets from entirely different eras are used. The highest performance accuracy value is 99, 12%; the performance rate at the attribute level is 98.246%; the level of techniques is 92.836%.
-next-
Recently, domain specific ontology development has been driven by research on the Semantic Web. Ontologies have been suggested for use in many application areas targeted by the Semantic Web, such as dynamic web service composition and general web service matching. Fundamental characteristics of these ontologies must be determined in order to effectively make use of them: for example, Sirin, Hendler and Parsia have suggested that determining fundamental characteristics of ontologies is important for dynamic web service composition. Our research examines cohesion metrics for ontologies. The cohesion metrics examine the fundamental quality of cohesion as it relates to ontologies.
-next-
Several classification algorithms for pattern recognition had been tested in the mapping of tropical forest cover using airborne hyperspectral data. Results from the use of Maximum Likelihood (ML), Spectral Angle Mapper (SAM), Artificial Neural Network (ANN) and Decision Tree (DT) classifiers were compared and evaluated. It was found that ML performed the best followed by ANN, DT and SAM with accuracies of 86%, 84%, 51% and 49% respectively. 
-next-
Mobile ad hoc networks(MANET) represent complex distributed systems that comprise wireless mobile nodes that can freely and dynamically self organize into arbitrary and temporary ad-hoc network topologies, allowing people and devices to seamlessly internet work in areas with no preexisting communication infrastructure e.g., disaster recovery environments. An ad-hoc network is not a new one, having been around in various forms for over 20 years. Traditionally, tactical networks have been the only communication networking application that followed the ad-hoc paradigm. Recently the introduction of new technologies such as Bluetooth, IEEE 802.11 and hyperlan are helping enable eventual commercial MANET deployments outside the military domain. These recent revolutions have been generating a renewed and growing interest in the research and development of MANET. To facilitate communication within the network a routing protocol is used to discover routes between nodes. The goal of the routing protocol is to have an efficient route establishment between a pair of nodes, so that messages can be delivered in a timely manner. Bandwidth and power constraints are the important factors to be considered in current wireless network because multi-hop ad-hoc wireless relies on each node in the network to act as a router and packet forwarder. This dependency places bandwidth, power computation demands on mobile host to be taken into account while choosing the protocol. Routing protocols used in wired network cannot be used for mobile ad-hoc networks because of node mobility. The ad-hoc routing protocols are divided into two classes: table driven and demand based. This paper reviews and discusses routing protocol belonging to each category. 
-next-
In today’s world there has been an exponential growth among smart-phone users which has led to the unbridled growth of smart-phone apps available in Google play store, app store etc., In case of android application, there are many free applications for which the user need not shell out a penny to use the services. Here the magic word is free which entices millions of pliant people into installing those apps and giving unnecessary access to their data and device control. Current studies have shown that over 70% of the apps in market, request to gather data digressive to the most functions of apps that might cause seeping of personal data or inefficient use of mobile resources. Of late, couple of malignant applications gather unobtrusive information of the user through third-party applications by increasing their permissions to high-level on the Android Operating System. Android permission system provides, the user access to the third party apps and in return based on the permissions granted by the user, an app can access the related resource from the user's mobile. A user is bound to grant or deny permits during the installation of the application. For the most part, users don't focus on the asked permissions, or sometimes users do not understand the meaning of the permission and install the app on their device. They allow a way for attackers to perform the malicious task by demanding for more than expected set of permissions. These extra permissions permit the attacker to exploit the device and also retrieve sensitive information from it. In this research paper we describe how permission system security can create an awareness among the users that would assist them in deciding on permission grants. This improved and responsible user activities in Android OS can help the users in utilizing their device securely.
-next-
This study is emphasized on different types of normalization. Each of which was tested against the ID3 methodology using the HSV data set. Number of leaf nodes, accuracy and tree growing time are three factors that were taken into account. Comparisons between different learning methods were accomplished as they were applied to each normalization method. A new matrix was designed to check for the best normalization method based on the factors and their priorities. Recommendations were concluded.
-next-
In this study, authorship attribution in Arabic poetry will be conducted to determine the authorship of a specified text after documents with recognized authorships have been allocated. This work also measures the impact performance of Naïve Bayes, Support Vector Machine and Linear discriminant analysis for Arabic poetry authorship attribution using text mining classification. Several features such as lexical features, character features, structural features, poetry features, syntactic features, semantic features and specific word features are utilized as the input data for text mining, using classification algorithms Linear discriminant analysis, Support Vector Machine and Naïve Bayes by Arabic Poetry Authorship Attribution Model (APAAM). The dataset of Arabic poetry is divided into two sets: known poetic in training dataset texts and anonymous poetic texts in a test dataset part. In the experiment, a set of 114 random poets from entirely different eras are used. The highest performance accuracy value is 99, 12%; the performance rate at the attribute level is 98.246%; the level of techniques is 92.836%.
-next-
Problem statement: The synthesis of a command by the neural network has an excellent advantage over the classical one such as PID. This study presented a fast and accurate Wavelet Neural Network (WNN) approach for efficient controlling of an Active Magnetic Bearing (AMB) system. Approach: The proposed approach combined neural network with the wavelet theory. Wavelet theory may be exploited in deriving a good initialization for the neural network and thus improved convergence of the learning algorithm. Results: We tested two control systems based on three types of neural controllers: Multiplayer Perceptron (MLP) controller, RBF Neural Network (RBFNN) controller and WNN controller. The simulation results show that the proposed WNN controller provides better performance comparing with standard PID controller, MLP and RBFNN controllers. Conclusion: The proposed WNN approach was shown to be useful in controlling nonlinear dynamic mechanical system, such as the AMB system used in this study.
-next-
Problem statement: This research had done the software design and database system model for Payroll Management System (PMS) in Defense Institute of Physiology and Allied Sciences (DIPAS). The calculations are based on the user provided employees details like basic pay, house rent allowance, loan details and so on. Based on these user inputs the system automatically generates pay slip, pay bills, all schedules for debit and credit payments. This system is developed in such a way to suit for both new and old pension schemes of the central government employees of India. The use of Java Server Pages (JSP) language for system development allows easy modification of the system design. So the system design can be directly implemented to any other central government organization with slight modifications. Approach: This study presented the database and software design for PMS. The software changes the manual operation into a computer-based system to automate study, provide efficiency, accuracy, timelessness, security and economy. Results: After undertaking an in-depth examination of the existing manual payroll management system and analyzing its short comings, it has been found necessary to remove its deficiencies and provide a suitable solution for presently encountered problem. Conclusion: The proposed system can help the organization to manage efficiently the employee pay related data as personal information, salary information, loan information and so on.
-next-
Healthcare professionals spend much of their time wandering between patients and offices, while the supportive technology stays stationary. Therefore, mobile applications has adapted for healthcare industry. In spite of the advancement and variety of available mobile based applications, there is an eminent need to investigate the current position of the acceptance of those mobile health applications that are tailored towards the tracking patients condition, share patients information and access. Consequently, in this study Technology Acceptance Model has designed to investigate the user acceptance of mobile technology application within healthcare industry. The purpose of this study is to design a quantitative approach based on the technology acceptance model questionnaire as its primary research methodology. It utilized a quantitative approach based a Technology Acceptance Model (TAM) to evaluate the system mobile tracking Model. The related constructs for evaluation are: Perceived of Usefulness, Perceived Ease of Use, User Satisfaction and Attribute of Usability. All these constructs are modified to suit the context of the study. Moreover, this study outlines the details of each construct and its relevance toward the research issue. The outcome of the study represents series of approaches that will apply for checking the suitability of a mobile tracking on patient progress application for health care industry and how well it achieves the aims and objectives of the design.
-next-
Problem statement: Clustering is one of the most important research areas in the field of data mining. Clustering means creating groups of objects based on their features in such a way that the objects belonging to the same groups are similar and those belonging to different groups are dissimilar. Clustering is an unsupervised learning technique. The main advantage of clustering is that interesting patterns and structures can be found directly from very large data sets with little or none of the background knowledge. Clustering algorithms can be applied in many domains. Approach: In this research, the most representative algorithms K-Means and K-Medoids were examined and analyzed based on their basic approach. The best algorithm in each category was found out based on their performance. The input data points are generated by two ways, one by using normal distribution and another by applying uniform distribution. Results: The randomly distributed data points were taken as input to these algorithms and clusters are found out for each algorithm. The algorithms were implemented using JAVA language and the performance was analyzed based on their clustering quality. The execution time for the algorithms in each category was compared for different runs. The accuracy of the algorithm was investigated during different execution of the program on the input data points. Conclusion: The average time taken by K-Means algorithm is greater than the time taken by K-Medoids algorithm for both the case of normal and uniform distributions. The results proved to be satisfactory.
-next-
The proliferation of digitized media due to the rapid growth of networked multimedia systems, has created an urgent need for copyright enforcement technologies that can protect copyright ownership of multimedia objects. Digital image watermarking is one such technology that has been developed to protect digital images from illegal manipulations. In particular, digital image watermarking algorithms which are based on the discrete wavelet transform have been widely recognized to be more prevalent than others. This is due to the wavelets' excellent spatial localization, frequency spread, and multi-resolution characteristics, which are similar to the theoretical models of the human visual system. In this paper, we describe an imperceptible and a robust combined DWT-DCT digital image watermarking algorithm. The algorithm watermarks a given digital image using a combination of the Discrete Wavelet Transform (DWT) and the Discrete Cosine Transform (DCT). Performance evaluation results show that combining the two transforms improved the performance of the watermarking algorithms that are based solely on the DWT transform.
-next-
In this study we present our initial idea for using genetic algorithms to help a controllable mobile robot to find an optimal path between a starting and ending point in a grid environment. The mobile robot has to find the optimal path which reduces the number of steps to be taken between the starting point and the target ending point. GAs can overcome many problems encountered by traditional search techniques such as the gradient based methods. The proposed controlling algorithm allows four-neighbor movements, so that path-planning can adapt with complicated search spaces with low complexities. The results are promising.
-next-
Several classification algorithms for pattern recognition had been tested in the mapping of tropical forest cover using airborne hyperspectral data. Results from the use of Maximum Likelihood (ML), Spectral Angle Mapper (SAM), Artificial Neural Network (ANN) and Decision Tree (DT) classifiers were compared and evaluated. It was found that ML performed the best followed by ANN, DT and SAM with accuracies of 86%, 84%, 51% and 49% respectively. 
-next-
Endoscopy is the routine medical procedure to observe tumors in the human Gastrointestinal (GI) tract by inserting an endoscope, a thin, flexible, tube-like instrument with a light source and camera. Traditionally, an endoscopist performs the endoscopy, orients the endoscope within these structures and navigates this through the help of familiar anatomical landmarks to reach the abnormalities and mark them. Identifying landmarks and abnormalities is critical for the maneuver and the success of endoscopy, which is related to the patient’s comfort, injury and accurate diagnosis. The manual naked-eye-observation maneuver and examination are highly challenging, take a long time and often cause discomfort to the patients and the endoscopists. As a result, several AI-based landmark detection methods have been proposed recently to facilitate autonomous endoscopy examination. However, these methods lack accuracy and consider only limited landmarks. This study presents a Data-efficient image Transformer (DeiT)-based method to detect anatomical landmarks and anomalies for autonomous endoscopy. The proposed method detected 23 landmarks and anomalies from the entire GI tract with 99% accuracy and precision, outperforming the state-of-the-art (91%). Moreover, this method took only 0.045 sec to identify a landmark. The phi coefficient (0.997) indicated a strong positive association between the proposed method and clinical ground truth. Strong association, high accuracy and rapid speed ensured the reliability of the proposed method for autonomous endoscopy examination.
